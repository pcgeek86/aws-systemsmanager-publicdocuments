{
  "AttachmentsContent": [],
  "Content": "{\n  \"description\" : \"## Id\\nAWSResilienceHub-ForceSQSStandardQueueMaxReceiveFailureTest_2020-11-27\\n\\n## Intent\\nTest standard SQS behavior after receiving a message maximum allowed times. Wait for alarm for metric ApproximateNumberOfMessagesVisible for DLQ to trigger when number of messages on DLQ is more than 0\\n\\n## Type\\nTEST\\n\\n## Risk\\nHigh\\n\\n## Requirements:\\n  * standard SQS queue with DLQ redrive policy set up\\n  * Amazon CloudWatch alarm is setup for [ApproximateNumberOfMessagesVisible](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-available-cloudwatch-metrics.html) metric for DLQ. Should trigger when number messages is more than 0\\n\\n## Depends on\\nAWSResilienceHub-MoveSQSMessagesBetweenQueuesSOP_2021-03-11\\n\\n## Permissions required for AutomationAssumeRole\\n* cloudwatch:DescribeAlarms\\n* sqs:GetQueueAttributes\\n* sqs:SetQueueAttributes\\n* sqs:ReceiveMessage\\n* sqs:SendMessage\\n* sqs:DeleteMessage\\n* sqs:GetQueueUrl\\n* ssm:StartAutomationExecution\\n* ssm:GetAutomationExecution\\n* ssm:GetParameters\\n* iam:PassRole\\n\\n##### In case queues are encrypted with a KMS key\\n  * kms:GenerateDataKey\\n  * kms:Decrypt\\n  * kms:Encrypt\\n\\n##### To log output to CloudWatch\\n  * logs:CreateLogStream\\n  * logs:PutLogEvents\\n  * logs:DescribeLogGroups\\n  * logs:DescribeLogStreams\\n\\n## Supports Rollback\\nYes. The document reverts redrive policy and visibility timeout and moves messages back from DLQ\\n\\n## Cancellation behavior\\nThe document reverts redrive policy and visibility timeout and moves messages back from DLQ\\n\\n## Inputs\\n### (Required) AutomationAssumeRole\\n  * type: String\\n  * description: ARN of the IAM role with permissions listed above\\n\\n### (Required) QueueUrl\\n  * type: String\\n  * description: The URL of the SQS queue\\n\\n### (Required) DeadLetterQueueAlarmName\\n  * type: String\\n  * description: Amazon CloudWatch alarm for [ApproximateNumberOfMessagesVisible](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-available-cloudwatch-metrics.html) metric for DLQ. Should trigger when number messages is more than 0\\n\\n### (Optional) IsRollback\\n  * type: String\\n  * description: Run the rollback steps of the document. True or False. If True, the parameter PreviousExecutionId should also be specified\\n  * default: false\\n\\n### (Optional) PreviousExecutionId\\n  * type: String\\n  * description: SSM execution ID of the previous execution of this document for which resources need to be cleaned up\\n\\n## Details\\nThe document injects failure by setting redrive policy to a small number of retries and visibility timeout\\nto zero and reading messages until they get redriven to DLQ. After test the document executes\\nAWSResilienceHub-MoveSQSMessagesBetweenQueuesSOP_2021-03-11 SOP to move all messages back from DLQ. Note that messages\\nthat have been already present in the DLQ before the test will also be moved to the main queue.\\nIn case of issues users should manually remove messages from DLQ or use\\nAWSResilienceHub-MoveSQSMessagesBetweenQueuesSOP_2021-03-11 document to send them back.\\n\\n## Steps executed in normal flow\\n  * CheckIsRollback\\n  * AssertAlarmToBeGreenBeforeTest\\n  * BackupCurrentExecution\\n  * GetUpdatedRedrivePolicy\\n  * SetQueueAttributes\\n  * ReadMessage\\n  * AssertAlarmToBeRed\\n  * GetDeadLetterQueueUrl\\n  * RollbackCurrentExecution\\n  * SleepBeforeGetNumberOfMessagesToMove\\n  * GetNumberOfMessagesToMove\\n  * MoveMessages\\n  * AssertAlarmToBeGreen\\n\\n## Steps executed in rollback flow\\n  * CheckIsRollback\\n  * GetQueueUrlFromPreviousExecution\\n  * AssertQueueUrl\\n  * PrepareRollbackOfPreviousExecutionQueueAttributes\\n  * GetDeadLetterQueueUrlFromPreviousExecution\\n  * RollbackPreviousExecutionQueueAttributes\\n  * GetDLQVisibilityTimeout\\n  * WaitForDLQVisibilityTimeout\\n  * GetNumberOfMessagesToMoveForPreviousExecution\\n  * MoveMessagesForPreviousExecution\\n\\n## Outputs\\nNone\",\n  \"schemaVersion\" : \"0.3\",\n  \"assumeRole\" : \"{{ AutomationAssumeRole }}\",\n  \"parameters\" : {\n    \"QueueUrl\" : {\n      \"type\" : \"String\",\n      \"description\" : \"(Required) The URL of the queue\"\n    },\n    \"AutomationAssumeRole\" : {\n      \"type\" : \"String\",\n      \"description\" : \"(Required) The ARN of the role that allows Automation to perform the actions on your behalf.\"\n    },\n    \"DeadLetterQueueAlarmName\" : {\n      \"type\" : \"String\",\n      \"description\" : \"(Required) Alarm which should be red after injection of the failure and green after the rollback process in the end of the test.\"\n    },\n    \"IsRollback\" : {\n      \"type\" : \"String\",\n      \"description\" : \"(Optional) Run the rollback steps of the document. True or False. If True, the parameter PreviousExecutionId should also be specified\",\n      \"default\" : \"false\"\n    },\n    \"PreviousExecutionId\" : {\n      \"type\" : \"String\",\n      \"description\" : \"(Optional) SSM execution ID of the previous execution of this document for which resources need to be cleaned up\",\n      \"default\" : \"\"\n    }\n  },\n  \"mainSteps\" : [ {\n    \"name\" : \"CheckIsRollback\",\n    \"description\" : \"Check if document should be executed in rollback mode\",\n    \"action\" : \"aws:branch\",\n    \"inputs\" : {\n      \"Choices\" : [ {\n        \"NextStep\" : \"GetQueueUrlFromPreviousExecution\",\n        \"Variable\" : \"{{ IsRollback }}\",\n        \"EqualsIgnoreCase\" : \"true\"\n      } ],\n      \"Default\" : \"AssertAlarmToBeGreenBeforeTest\"\n    }\n  }, {\n    \"name\" : \"GetQueueUrlFromPreviousExecution\",\n    \"description\" : \"Get input from previous execution. This will be used to validate that rollback is executed with the same input\",\n    \"action\" : \"aws:executeScript\",\n    \"outputs\" : [ {\n      \"Name\" : \"QueueUrl\",\n      \"Selector\" : \"$.Payload.QueueUrl[0]\",\n      \"Type\" : \"String\"\n    } ],\n    \"inputs\" : {\n      \"Runtime\" : \"python3.8\",\n      \"Handler\" : \"get_inputs_from_ssm_execution\",\n      \"InputPayload\" : {\n        \"ExecutionId\" : \"{{ PreviousExecutionId }}\"\n      },\n      \"Script\" : \"import json\\nimport boto3\\nfrom botocore.config import Config\\n\\n\\n\\n\\ndef get_inputs_from_ssm_execution(events, context):\\n    output = {}\\n    config = Config(retries={'max_attempts': 20, 'mode': 'standard'})\\n    ssm = boto3.client('ssm', config=config)\\n\\n    if 'ExecutionId' not in events:\\n        raise KeyError('Requires ExecutionId')\\n\\n    if not events['ExecutionId']:\\n        raise KeyError('Requires not empty ExecutionId')\\n\\n    response = ssm.get_automation_execution(AutomationExecutionId=events['ExecutionId'])\\n    response_parameters = response['AutomationExecution']['Parameters']\\n    # TODO DIG-853\\n    for parameter in response_parameters:\\n        output[parameter] = response_parameters[parameter]\\n\\n    return output\"\n    }\n  }, {\n    \"name\" : \"AssertQueueUrl\",\n    \"description\" : \"Validate that rollback is executed with the same input\",\n    \"action\" : \"aws:branch\",\n    \"inputs\" : {\n      \"Choices\" : [ {\n        \"NextStep\" : \"PrepareRollbackOfPreviousExecutionQueueAttributes\",\n        \"Variable\" : \"{{ GetQueueUrlFromPreviousExecution.QueueUrl }}\",\n        \"StringEquals\" : \"{{ QueueUrl }}\"\n      } ]\n    },\n    \"isEnd\" : true\n  }, {\n    \"name\" : \"PrepareRollbackOfPreviousExecutionQueueAttributes\",\n    \"description\" : \"Get initital queue redrive policy\",\n    \"action\" : \"aws:executeScript\",\n    \"outputs\" : [ {\n      \"Name\" : \"RedrivePolicy\",\n      \"Selector\" : \"$.Payload.RedrivePolicy[0]\",\n      \"Type\" : \"String\"\n    }, {\n      \"Name\" : \"VisibilityTimeout\",\n      \"Selector\" : \"$.Payload.VisibilityTimeout[0]\",\n      \"Type\" : \"String\"\n    } ],\n    \"inputs\" : {\n      \"Runtime\" : \"python3.8\",\n      \"Handler\" : \"get_output_from_ssm_step_execution\",\n      \"InputPayload\" : {\n        \"ExecutionId\" : \"{{ PreviousExecutionId }}\",\n        \"StepName\" : \"BackupCurrentExecution\",\n        \"ResponseField\" : \"VisibilityTimeout,RedrivePolicy\"\n      },\n      \"Script\" : \"import json\\nimport boto3\\nfrom botocore.config import Config\\n\\n\\n\\n\\ndef get_output_from_ssm_step_execution(events, context):\\n    config = Config(retries={'max_attempts': 20, 'mode': 'standard'})\\n    ssm = boto3.client('ssm', config=config)\\n\\n    if 'ExecutionId' not in events or 'StepName' not in events or 'ResponseField' not in events:\\n        raise KeyError('Requires ExecutionId, StepName and ResponseField in events')\\n\\n    ssm_response = ssm.get_automation_execution(AutomationExecutionId=events['ExecutionId'])\\n    for step in ssm_response['AutomationExecution']['StepExecutions']:\\n        if step['StepName'] == events['StepName']:\\n            response_fields = events['ResponseField'].split(',')\\n            output = {}\\n            for response_field in response_fields:\\n                if response_field in step['Outputs']:\\n                    # Sets values in string type regardless of what is the original value type. In order to set\\n                    # values with original types please use 'get_typed_output_from_ssm_step_execution'.\\n                    output[response_field] = step['Outputs'][response_field]\\n                else:\\n                    \\\"\\\"\\\"\\n                    By default SSM ignores empty values when encodes API outputs to JSON. It may result in\\n                    a situation when an empty value is a valid value but step output completely misses it.\\n                    Usually happens with SQS queue policies, default policy is returned by API as an empty value\\n                    and executeApi step output ignores it. As a result, further steps in rollback execution will fail.\\n                    Instead of ignoring this value we should use a default empty value in rollback, i.e. empty string\\n                    represents a default sqs policy\\n                    \\\"\\\"\\\"\\n                    output[response_field] = ['']\\n            return output\\n\\n    # Could not find step name\\n    raise Exception('Can not find step name % in ssm execution response', events['StepName'])\"\n    }\n  }, {\n    \"name\" : \"GetDeadLetterQueueUrlFromPreviousExecution\",\n    \"description\" : \"Get DLQ URL from redrive policy\",\n    \"action\" : \"aws:executeScript\",\n    \"outputs\" : [ {\n      \"Name\" : \"QueueUrl\",\n      \"Selector\" : \"$.Payload.QueueUrl\",\n      \"Type\" : \"String\"\n    } ],\n    \"inputs\" : {\n      \"Runtime\" : \"python3.8\",\n      \"Handler\" : \"get_dead_letter_queue_url\",\n      \"InputPayload\" : {\n        \"SourceRedrivePolicy\" : \"{{ PrepareRollbackOfPreviousExecutionQueueAttributes.RedrivePolicy }}\"\n      },\n      \"Script\" : \"import json\\nimport logging\\nimport time\\nimport uuid\\nimport boto3\\nimport random\\nfrom datetime import datetime\\nfrom typing import List, Callable, Optional\\nfrom botocore.exceptions import ClientError\\nfrom botocore.config import Config\\n\\nlogger = logging.getLogger()\\nlogger.setLevel(logging.INFO)\\n\\n\\n\\n\\ndef get_dead_letter_queue_url(events: dict, context: dict) -> dict:\\n    \\\"\\\"\\\"\\n    Retrieves dead-letter queue URL by RedrivePolicy\\n    \\\"\\\"\\\"\\n    if \\\"SourceRedrivePolicy\\\" not in events:\\n        raise KeyError(\\\"Requires SourceRedrivePolicy in events\\\")\\n\\n    source_redrive_policy: str = events.get(\\\"SourceRedrivePolicy\\\")\\n    if not source_redrive_policy:\\n        raise KeyError(\\\"Requires not empty SourceRedrivePolicy\\\")\\n    config = Config(retries={'max_attempts': 20, 'mode': 'standard'})\\n    sqs_client = boto3.client(\\\"sqs\\\", config=config)\\n    source_redrive_policy: dict = json.loads(source_redrive_policy)\\n    dead_letter_queue_name: str = source_redrive_policy.get(\\\"deadLetterTargetArn\\\").split(':', 5)[5]\\n    get_queue_url_response: dict = sqs_client.get_queue_url(QueueName=dead_letter_queue_name)\\n    dead_letter_queue_url: str = get_queue_url_response['QueueUrl']\\n\\n    return {\\\"QueueUrl\\\": dead_letter_queue_url}\"\n    }\n  }, {\n    \"name\" : \"RollbackPreviousExecutionQueueAttributes\",\n    \"description\" : \"Revert initial redrive policy\",\n    \"action\" : \"aws:executeAwsApi\",\n    \"inputs\" : {\n      \"Service\" : \"sqs\",\n      \"Api\" : \"SetQueueAttributes\",\n      \"QueueUrl\" : \"{{ GetQueueUrlFromPreviousExecution.QueueUrl }}\",\n      \"Attributes\" : {\n        \"VisibilityTimeout\" : \"{{ PrepareRollbackOfPreviousExecutionQueueAttributes.VisibilityTimeout }}\",\n        \"RedrivePolicy\" : \"{{ PrepareRollbackOfPreviousExecutionQueueAttributes.RedrivePolicy }}\"\n      }\n    }\n  }, {\n    \"name\" : \"GetDLQVisibilityTimeout\",\n    \"description\" : \"Get DLQ visibility timeout value\",\n    \"action\" : \"aws:executeAwsApi\",\n    \"outputs\" : [ {\n      \"Name\" : \"VisibilityTimeout\",\n      \"Selector\" : \"$.Attributes.VisibilityTimeout\",\n      \"Type\" : \"String\"\n    } ],\n    \"inputs\" : {\n      \"Service\" : \"sqs\",\n      \"Api\" : \"GetQueueAttributes\",\n      \"AttributeNames\" : [ \"VisibilityTimeout\" ],\n      \"QueueUrl\" : \"{{ GetDeadLetterQueueUrlFromPreviousExecution.QueueUrl }}\"\n    }\n  }, {\n    \"name\" : \"WaitForDLQVisibilityTimeout\",\n    \"description\" : \"Wait for DLQ visiblity timeout time to ensure all messages are visible\",\n    \"action\" : \"aws:sleep\",\n    \"inputs\" : {\n      \"Duration\" : \"PT{{ GetDLQVisibilityTimeout.VisibilityTimeout }}S\"\n    }\n  }, {\n    \"name\" : \"GetNumberOfMessagesToMoveForPreviousExecution\",\n    \"description\" : \"Count number of messages on DLQ to be moved back\",\n    \"action\" : \"aws:executeAwsApi\",\n    \"outputs\" : [ {\n      \"Name\" : \"ApproximateNumberOfMessages\",\n      \"Selector\" : \"$.Attributes.ApproximateNumberOfMessages\",\n      \"Type\" : \"String\"\n    } ],\n    \"inputs\" : {\n      \"Service\" : \"sqs\",\n      \"Api\" : \"GetQueueAttributes\",\n      \"AttributeNames\" : [ \"ApproximateNumberOfMessages\" ],\n      \"QueueUrl\" : \"{{ GetDeadLetterQueueUrlFromPreviousExecution.QueueUrl }}\"\n    }\n  }, {\n    \"name\" : \"MoveMessagesForPreviousExecution\",\n    \"description\" : \"Execute AWSResilienceHub-MoveSQSMessagesBetweenQueuesSOP_2021-03-11 SOP to move messages back from DLQ to queue\",\n    \"action\" : \"aws:executeAutomation\",\n    \"maxAttempts\" : 3,\n    \"timeoutSeconds\" : 600,\n    \"onFailure\" : \"Abort\",\n    \"inputs\" : {\n      \"DocumentName\" : \"AWSResilienceHub-MoveSQSMessagesBetweenQueuesSOP_2021-03-11\",\n      \"RuntimeParameters\" : {\n        \"SourceQueueUrl\" : \"{{ GetDeadLetterQueueUrlFromPreviousExecution.QueueUrl }}\",\n        \"TargetQueueUrl\" : \"{{ GetQueueUrlFromPreviousExecution.QueueUrl }}\",\n        \"NumberOfMessagesToTransfer\" : \"{{ GetNumberOfMessagesToMoveForPreviousExecution.ApproximateNumberOfMessages }}\",\n        \"AutomationAssumeRole\" : \"{{ AutomationAssumeRole }}\"\n      }\n    },\n    \"isEnd\" : true\n  }, {\n    \"name\" : \"AssertAlarmToBeGreenBeforeTest\",\n    \"description\" : \"Ensure alarm is green before starting test. Fail if alarm is not green within expected time\",\n    \"action\" : \"aws:waitForAwsResourceProperty\",\n    \"timeoutSeconds\" : 1200,\n    \"inputs\" : {\n      \"Service\" : \"cloudwatch\",\n      \"Api\" : \"DescribeAlarms\",\n      \"AlarmNames\" : [ \"{{ DeadLetterQueueAlarmName }}\" ],\n      \"PropertySelector\" : \"$.MetricAlarms[0].StateValue\",\n      \"DesiredValues\" : [ \"OK\" ]\n    }\n  }, {\n    \"name\" : \"BackupCurrentExecution\",\n    \"description\" : \"Backup initial redrive policy for rollback\",\n    \"action\" : \"aws:executeAwsApi\",\n    \"outputs\" : [ {\n      \"Name\" : \"QueueArn\",\n      \"Selector\" : \"$.Attributes.QueueArn\",\n      \"Type\" : \"String\"\n    }, {\n      \"Name\" : \"VisibilityTimeout\",\n      \"Selector\" : \"$.Attributes.VisibilityTimeout\",\n      \"Type\" : \"String\"\n    }, {\n      \"Name\" : \"RedrivePolicy\",\n      \"Selector\" : \"$.Attributes.RedrivePolicy\",\n      \"Type\" : \"String\"\n    } ],\n    \"inputs\" : {\n      \"Service\" : \"sqs\",\n      \"Api\" : \"GetQueueAttributes\",\n      \"AttributeNames\" : [ \"QueueArn\", \"VisibilityTimeout\", \"RedrivePolicy\" ],\n      \"QueueUrl\" : \"{{ QueueUrl }}\"\n    }\n  }, {\n    \"name\" : \"GetUpdatedRedrivePolicy\",\n    \"description\" : \"Generate redrive policy with small receive count to force messages go to DLQ\",\n    \"action\" : \"aws:executeScript\",\n    \"outputs\" : [ {\n      \"Name\" : \"RedrivePolicy\",\n      \"Selector\" : \"$.Payload.RedrivePolicy\",\n      \"Type\" : \"String\"\n    } ],\n    \"inputs\" : {\n      \"Runtime\" : \"python3.8\",\n      \"Handler\" : \"update_max_receive_count\",\n      \"InputPayload\" : {\n        \"SourceRedrivePolicy\" : \"{{ BackupCurrentExecution.RedrivePolicy }}\",\n        \"MaxReceiveCount\" : 1\n      },\n      \"Script\" : \"import json\\nimport logging\\nimport time\\nimport uuid\\nimport boto3\\nimport random\\nfrom datetime import datetime\\nfrom typing import List, Callable, Optional\\nfrom botocore.exceptions import ClientError\\nfrom botocore.config import Config\\n\\nlogger = logging.getLogger()\\nlogger.setLevel(logging.INFO)\\n\\n\\n\\n\\ndef update_max_receive_count(events: dict, context: dict) -> dict:\\n    \\\"\\\"\\\"\\n    Update SQS Redrive Policy with new value of MaxReceiveCount\\n    \\\"\\\"\\\"\\n    if \\\"SourceRedrivePolicy\\\" not in events or \\\"MaxReceiveCount\\\" not in events:\\n        raise KeyError(\\\"Requires SourceRedrivePolicy and MaxReceiveCount in events\\\")\\n\\n    source_redrive_policy: str = events.get(\\\"SourceRedrivePolicy\\\")\\n    if not source_redrive_policy:\\n        raise KeyError(\\\"Requires not empty SourceRedrivePolicy\\\")\\n\\n    max_receive_count: int = events.get(\\\"MaxReceiveCount\\\")\\n    if not 1 <= max_receive_count <= 1000:\\n        raise KeyError(\\\"Requires MaxReceiveCount to be in a range 1...1000\\\")\\n\\n    source_redrive_policy: dict = json.loads(source_redrive_policy)\\n    redrive_policy: dict = {\\n        \\\"deadLetterTargetArn\\\": source_redrive_policy.get(\\\"deadLetterTargetArn\\\"),\\n        \\\"maxReceiveCount\\\": max_receive_count\\n    }\\n\\n    return {\\\"RedrivePolicy\\\": json.dumps(redrive_policy)}\"\n    }\n  }, {\n    \"name\" : \"SetQueueAttributes\",\n    \"description\" : \"Set queue redrive policy to the generated one\",\n    \"action\" : \"aws:executeAwsApi\",\n    \"onFailure\" : \"step:RollbackCurrentExecution\",\n    \"onCancel\" : \"step:TriggerRollback\",\n    \"inputs\" : {\n      \"Service\" : \"sqs\",\n      \"Api\" : \"SetQueueAttributes\",\n      \"QueueUrl\" : \"{{ QueueUrl }}\",\n      \"Attributes\" : {\n        \"RedrivePolicy\" : \"{{ GetUpdatedRedrivePolicy.RedrivePolicy }}\",\n        \"VisibilityTimeout\" : \"0\"\n      }\n    }\n  }, {\n    \"name\" : \"ReadMessage\",\n    \"description\" : \"Read messages on queue until they are moved to DLQ\",\n    \"action\" : \"aws:executeScript\",\n    \"onFailure\" : \"step:GetDeadLetterQueueUrl\",\n    \"onCancel\" : \"step:TriggerRollback\",\n    \"inputs\" : {\n      \"Runtime\" : \"python3.8\",\n      \"Handler\" : \"receive_messages_by_events\",\n      \"InputPayload\" : {\n        \"QueueUrl\" : \"{{ QueueUrl }}\",\n        \"MaxNumberOfMessages\" : 2,\n        \"WaitTimeSeconds\" : 20,\n        \"RedrivePolicy\" : \"{{ BackupCurrentExecution.RedrivePolicy }}\",\n        \"VisibilityTimeout\" : 0\n      },\n      \"Script\" : \"import json\\nimport logging\\nimport time\\nimport uuid\\nimport boto3\\nimport random\\nfrom datetime import datetime\\nfrom typing import List, Callable, Optional\\nfrom botocore.exceptions import ClientError\\nfrom botocore.config import Config\\n\\nlogger = logging.getLogger()\\nlogger.setLevel(logging.INFO)\\n\\n\\n\\n\\ndef get_number_of_messages(queue_url: str) -> int:\\n    \\\"\\\"\\\"\\n    Util function to get approximate number of messages from the queue\\n    \\\"\\\"\\\"\\n    sqs_client = boto3.client(\\\"sqs\\\")\\n    response = sqs_client.get_queue_attributes(\\n        QueueUrl=queue_url,\\n        AttributeNames=[\\n            'ApproximateNumberOfMessages'\\n        ]\\n    )\\n    return int(response['Attributes']['ApproximateNumberOfMessages'])\\n\\n\\n\\ndef get_dead_letter_queue_url(events: dict, context: dict) -> dict:\\n    \\\"\\\"\\\"\\n    Retrieves dead-letter queue URL by RedrivePolicy\\n    \\\"\\\"\\\"\\n    if \\\"SourceRedrivePolicy\\\" not in events:\\n        raise KeyError(\\\"Requires SourceRedrivePolicy in events\\\")\\n\\n    source_redrive_policy: str = events.get(\\\"SourceRedrivePolicy\\\")\\n    if not source_redrive_policy:\\n        raise KeyError(\\\"Requires not empty SourceRedrivePolicy\\\")\\n    config = Config(retries={'max_attempts': 20, 'mode': 'standard'})\\n    sqs_client = boto3.client(\\\"sqs\\\", config=config)\\n    source_redrive_policy: dict = json.loads(source_redrive_policy)\\n    dead_letter_queue_name: str = source_redrive_policy.get(\\\"deadLetterTargetArn\\\").split(':', 5)[5]\\n    get_queue_url_response: dict = sqs_client.get_queue_url(QueueName=dead_letter_queue_name)\\n    dead_letter_queue_url: str = get_queue_url_response['QueueUrl']\\n\\n    return {\\\"QueueUrl\\\": dead_letter_queue_url}\\n\\n\\n\\ndef receive_messages(source_queue_url: str, messages_transfer_batch_size: int, wait_timeout: int = 0) -> \\\\\\n        Optional[List[dict]]:\\n    \\\"\\\"\\\"\\n    Receive messages\\n    :param wait_timeout: The duration i seconds for which the call waits for a message to arrive in the queue\\n    :param messages_transfer_batch_size: how many messages to receive\\n    :param source_queue_url:  URL of the queue where from messages are received\\n    :return: response of receive_message method\\n    \\\"\\\"\\\"\\n    config = Config(retries={'max_attempts': 20, 'mode': 'standard'})\\n    sqs_client = boto3.client(\\\"sqs\\\", config=config)\\n    receive_message_response: dict = \\\\\\n        sqs_client.receive_message(QueueUrl=source_queue_url,\\n                                   MaxNumberOfMessages=messages_transfer_batch_size,\\n                                   WaitTimeSeconds=wait_timeout,\\n                                   MessageAttributeNames=['All'],\\n                                   AttributeNames=['All'])\\n    return receive_message_response.get('Messages')\\n\\n\\n\\ndef receive_messages_by_events(events: dict, context: dict) -> dict:\\n    \\\"\\\"\\\"\\n    Receive messages using events as an input and invoke method receive_messages\\n    :param context:\\n    :param events:\\n        'QueueUrl': URL of the queue where from messages are received\\n        'MaxNumberOfMessages': how many messages to receive\\n        'WaitTimeSeconds': duration in seconds for which the call waits for a message to arrive in the queue\\n        'ScriptTimeout': script timeout in seconds\\n        'RedrivePolicy': Redrive policy to check queue DLQ\\n        'MaxAttempts': Max number of read attempts\\n    :return: response of receive_message method\\n    \\\"\\\"\\\"\\n    if \\\"QueueUrl\\\" not in events:\\n        raise KeyError(\\\"Requires QueueUrl in events\\\")\\n\\n    if \\\"MaxNumberOfMessages\\\" in events and not 1 <= int(events['MaxNumberOfMessages']) <= 10:\\n        raise KeyError(\\\"Requires MaxNumberOfMessages to be in a range 1..10\\\")\\n\\n    queue_url = events['QueueUrl']\\n    script_timeout = int(events.get('ScriptTimeout', 300))\\n    wait_timeout_seconds = int(events.get('WaitTimeSeconds', 5))\\n    max_number_of_messages = int(events.get('MaxNumberOfMessages', 1))\\n    max_attempts = int(events.get('MaxAttempts', 10))\\n\\n    if \\\"RedrivePolicy\\\" not in events:\\n        raise KeyError(\\\"Requires RedrivePolicy in events to check DLQ\\\")\\n    dlq_url = get_dead_letter_queue_url({'SourceRedrivePolicy': events['RedrivePolicy']}, {})['QueueUrl']\\n\\n    start = datetime.now()\\n    attempt = 1\\n\\n    while (datetime.now() - start).total_seconds() < script_timeout and attempt <= max_attempts:\\n        attempt += 1\\n        received_messages = receive_messages(queue_url, max_number_of_messages, wait_timeout_seconds)\\n        if received_messages is not None and len(received_messages) != 0:\\n            # Check if messages arrived to DLQ\\n            logger.debug('Wait for DLQ to receive messages')\\n            received_dlq_messages = receive_messages(dlq_url, 10, 20)\\n            if received_dlq_messages and len(received_dlq_messages) > 0:\\n                logger.debug(f'DLQ has {len(received_dlq_messages)} messages')\\n                return {\\n                    \\\"NumberOfReadMessages\\\": len(received_messages),\\n                    \\\"NumberOfDLQMessages\\\": len(received_dlq_messages)\\n                }\\n            else:\\n                logger.debug('Messages not found in DLQ')\\n        else:\\n            logger.debug('Messages not received')\\n\\n    raise Exception('Could not read messages before timeout')\"\n    }\n  }, {\n    \"name\" : \"AssertAlarmToBeRed\",\n    \"description\" : \"Wait for expected alarm to be red after failure is injected\",\n    \"action\" : \"aws:waitForAwsResourceProperty\",\n    \"onFailure\" : \"step:GetDeadLetterQueueUrl\",\n    \"onCancel\" : \"step:TriggerRollback\",\n    \"timeoutSeconds\" : 1200,\n    \"inputs\" : {\n      \"Service\" : \"cloudwatch\",\n      \"Api\" : \"DescribeAlarms\",\n      \"AlarmNames\" : [ \"{{ DeadLetterQueueAlarmName }}\" ],\n      \"PropertySelector\" : \"$.MetricAlarms[0].StateValue\",\n      \"DesiredValues\" : [ \"ALARM\" ]\n    }\n  }, {\n    \"name\" : \"GetDeadLetterQueueUrl\",\n    \"description\" : \"Get DLQ URL from redrive policy\",\n    \"action\" : \"aws:executeScript\",\n    \"onCancel\" : \"step:TriggerRollback\",\n    \"outputs\" : [ {\n      \"Name\" : \"QueueUrl\",\n      \"Selector\" : \"$.Payload.QueueUrl\",\n      \"Type\" : \"String\"\n    } ],\n    \"inputs\" : {\n      \"Runtime\" : \"python3.8\",\n      \"Handler\" : \"get_dead_letter_queue_url\",\n      \"InputPayload\" : {\n        \"SourceRedrivePolicy\" : \"{{ BackupCurrentExecution.RedrivePolicy }}\"\n      },\n      \"Script\" : \"import json\\nimport logging\\nimport time\\nimport uuid\\nimport boto3\\nimport random\\nfrom datetime import datetime\\nfrom typing import List, Callable, Optional\\nfrom botocore.exceptions import ClientError\\nfrom botocore.config import Config\\n\\nlogger = logging.getLogger()\\nlogger.setLevel(logging.INFO)\\n\\n\\n\\n\\ndef get_dead_letter_queue_url(events: dict, context: dict) -> dict:\\n    \\\"\\\"\\\"\\n    Retrieves dead-letter queue URL by RedrivePolicy\\n    \\\"\\\"\\\"\\n    if \\\"SourceRedrivePolicy\\\" not in events:\\n        raise KeyError(\\\"Requires SourceRedrivePolicy in events\\\")\\n\\n    source_redrive_policy: str = events.get(\\\"SourceRedrivePolicy\\\")\\n    if not source_redrive_policy:\\n        raise KeyError(\\\"Requires not empty SourceRedrivePolicy\\\")\\n    config = Config(retries={'max_attempts': 20, 'mode': 'standard'})\\n    sqs_client = boto3.client(\\\"sqs\\\", config=config)\\n    source_redrive_policy: dict = json.loads(source_redrive_policy)\\n    dead_letter_queue_name: str = source_redrive_policy.get(\\\"deadLetterTargetArn\\\").split(':', 5)[5]\\n    get_queue_url_response: dict = sqs_client.get_queue_url(QueueName=dead_letter_queue_name)\\n    dead_letter_queue_url: str = get_queue_url_response['QueueUrl']\\n\\n    return {\\\"QueueUrl\\\": dead_letter_queue_url}\"\n    }\n  }, {\n    \"name\" : \"RollbackCurrentExecution\",\n    \"description\" : \"Revert redrive policy to initial state\",\n    \"action\" : \"aws:executeAwsApi\",\n    \"onCancel\" : \"step:TriggerRollback\",\n    \"inputs\" : {\n      \"Service\" : \"sqs\",\n      \"Api\" : \"SetQueueAttributes\",\n      \"QueueUrl\" : \"{{ QueueUrl }}\",\n      \"Attributes\" : {\n        \"RedrivePolicy\" : \"{{ BackupCurrentExecution.RedrivePolicy }}\",\n        \"VisibilityTimeout\" : \"{{ BackupCurrentExecution.VisibilityTimeout }}\"\n      }\n    }\n  }, {\n    \"name\" : \"SleepBeforeGetNumberOfMessagesToMove\",\n    \"description\" : \"Sleep for 1 minute for ApproximateNumberOfMessages metric to become stable\",\n    \"action\" : \"aws:sleep\",\n    \"onCancel\" : \"step:TriggerRollback\",\n    \"inputs\" : {\n      \"Duration\" : \"PT60S\"\n    }\n  }, {\n    \"name\" : \"GetNumberOfMessagesToMove\",\n    \"description\" : \"Get number of messages on DLQ to move back\",\n    \"action\" : \"aws:executeAwsApi\",\n    \"onCancel\" : \"step:TriggerRollback\",\n    \"outputs\" : [ {\n      \"Name\" : \"ApproximateNumberOfMessages\",\n      \"Selector\" : \"$.Attributes.ApproximateNumberOfMessages\",\n      \"Type\" : \"String\"\n    } ],\n    \"inputs\" : {\n      \"Service\" : \"sqs\",\n      \"Api\" : \"GetQueueAttributes\",\n      \"AttributeNames\" : [ \"ApproximateNumberOfMessages\" ],\n      \"QueueUrl\" : \"{{ GetDeadLetterQueueUrl.QueueUrl }}\"\n    }\n  }, {\n    \"name\" : \"MoveMessages\",\n    \"description\" : \"Execute AWSResilienceHub-MoveSQSMessagesBetweenQueuesSOP_2021-03-11 SOP to move messages back from DLQ\",\n    \"action\" : \"aws:executeAutomation\",\n    \"onCancel\" : \"step:TriggerRollback\",\n    \"maxAttempts\" : 3,\n    \"timeoutSeconds\" : 600,\n    \"onFailure\" : \"Abort\",\n    \"inputs\" : {\n      \"DocumentName\" : \"AWSResilienceHub-MoveSQSMessagesBetweenQueuesSOP_2021-03-11\",\n      \"RuntimeParameters\" : {\n        \"SourceQueueUrl\" : \"{{ GetDeadLetterQueueUrl.QueueUrl }}\",\n        \"TargetQueueUrl\" : \"{{ QueueUrl }}\",\n        \"NumberOfMessagesToTransfer\" : \"{{ GetNumberOfMessagesToMove.ApproximateNumberOfMessages }}\",\n        \"AutomationAssumeRole\" : \"{{ AutomationAssumeRole }}\"\n      }\n    }\n  }, {\n    \"name\" : \"AssertAlarmToBeGreen\",\n    \"description\" : \"Wait for the alarm to be green after test is complete\",\n    \"action\" : \"aws:waitForAwsResourceProperty\",\n    \"timeoutSeconds\" : 1200,\n    \"inputs\" : {\n      \"Service\" : \"cloudwatch\",\n      \"Api\" : \"DescribeAlarms\",\n      \"AlarmNames\" : [ \"{{ DeadLetterQueueAlarmName }}\" ],\n      \"PropertySelector\" : \"$.MetricAlarms[0].StateValue\",\n      \"DesiredValues\" : [ \"OK\" ]\n    },\n    \"isEnd\" : true\n  }, {\n    \"name\" : \"TriggerRollback\",\n    \"description\" : \"This step is executed when ssm document is cancelled while it was in progress. This step starts a new execution of document in rollback mode to rollback the changes made as part of normal execution\",\n    \"action\" : \"aws:executeScript\",\n    \"onFailure\" : \"Abort\",\n    \"outputs\" : [ {\n      \"Name\" : \"RollbackExecutionId\",\n      \"Selector\" : \"$.Payload.RollbackExecutionId\",\n      \"Type\" : \"String\"\n    } ],\n    \"inputs\" : {\n      \"Runtime\" : \"python3.8\",\n      \"Handler\" : \"start_rollback_execution\",\n      \"InputPayload\" : {\n        \"ExecutionId\" : \"{{automation:EXECUTION_ID}}\"\n      },\n      \"Script\" : \"import json\\nimport boto3\\nfrom botocore.config import Config\\n\\n\\n\\n\\ndef start_rollback_execution(events, context):\\n    output = {}\\n    config = Config(retries={'max_attempts': 20, 'mode': 'standard'})\\n    ssm = boto3.client('ssm', config=config)\\n\\n    if 'ExecutionId' not in events or not events['ExecutionId']:\\n        raise KeyError('Requires not empty ExecutionId')\\n\\n    response = ssm.get_automation_execution(AutomationExecutionId=events['ExecutionId'])\\n\\n    # Get parameters for current execution and add IsRollback and PreviousExecutionId\\n    response_parameters = response['AutomationExecution']['Parameters']\\n    response_parameters['IsRollback'] = ['true']\\n    response_parameters['PreviousExecutionId'] = [events['ExecutionId']]\\n\\n    rollback_execution_response = ssm.start_automation_execution(\\n        DocumentName=response['AutomationExecution']['DocumentName'],\\n        DocumentVersion=response['AutomationExecution']['DocumentVersion'],\\n        Parameters=response_parameters\\n    )\\n    output['RollbackExecutionId'] = rollback_execution_response['AutomationExecutionId']\\n    return output\"\n    },\n    \"isEnd\" : true\n  } ]\n}",
  "CreatedDate": "2022-04-25T18:54:20.799Z",
  "DisplayName": null,
  "DocumentFormat": {
    "Value": "JSON"
  },
  "DocumentType": {
    "Value": "Automation"
  },
  "DocumentVersion": "3",
  "Name": "AWSResilienceHub-ForceSQSStandardQueueMaxReceiveFailureTest_2020-11-27",
  "Requires": [],
  "ReviewStatus": null,
  "Status": {
    "Value": "Active"
  },
  "StatusInformation": null,
  "VersionName": null,
  "ResponseMetadata": {
    "RequestId": "5bf26a39-fb07-4beb-918c-5b2d20fa9de9",
    "Metadata": {},
    "ChecksumAlgorithm": 0,
    "ChecksumValidationStatus": 0
  },
  "ContentLength": 32917,
  "HttpStatusCode": 200,
  "LoggedAt": "2022-11-07T07:15:07.6635+00:00"
}
