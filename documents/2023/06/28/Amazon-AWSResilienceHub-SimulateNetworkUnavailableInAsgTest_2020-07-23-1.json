{
  "AttachmentsContent": [],
  "Content": "{\n  \"schemaVersion\" : \"0.3\",\n  \"description\" : \"## Intent\\n  Test that the application correctly alerts if Amazon EC2 ASG network is unavailable.\\n\\n## Type\\n  Test\\n\\n## Risk\\n  High\\n\\n## Requirements\\n  * ASG has more than 1 instances\\n  * EC2 instance with Linux OS\\n  * Multiple Unhealthy Hosts Alarm is setup for ASG\\n\\n## Permissions required for AutomationAssumeRole\\n  * ssm:GetParameters\\n  * ssm:DescribeInstanceInformation\\n  * ssm:SendCommand\\n  * ssm:ListCommands\\n  * ssm:ListCommandInvocations\\n  * cloudwatch:DescribeAlarms\\n  * cloudwatch:DescribeAlarmHistory\\n  * autoscaling:DescribeAutoScalingGroups\\n\\n## Supports Rollback\\n  No.\\n\\n## Cancellation behavior\\n  Abort execution.\\n\\n## Inputs\\n### (Required) AutomationAssumeRole:\\n  * type: String\\n  * description: (Required) The ARN of the role that allows Automation to perform the actions on your behalf\\n  * allowedPattern: arn:aws:iam::\\\\d+:\\\\S+\\n\\n### (Required) AutoScalingGroupName:\\n  * type: String\\n  * description: (Required) Name of auto scaling group\\n\\n### (Required) UnhealthyHostsCountAlarmName:\\n  * type: String\\n  * description: (Required) An alarm for your Amazon Elastic Load Balancer that should be triggered when a new host becomes unhealthy. This alarm should be based on the UnHealthyHostCount metric, \\n    and its namespace will depend on the type of load balancer used.\\n\\n### (Optional) PercentageOfInstances:\\n  * type: Integer\\n  * description: (Optional) Percentage of ASG EC2 instances to be impacted, default is 1 percent to put minimum impact on EC2 instances in case if not provided\\n  * default: 1\\n\\n### (Optional) DurationInMinutes:\\n  * type: String\\n  * description: (Optional) The expected recovery time after process dies (default 10)\\n  * default: '10'\\n  * allowedPattern: ^\\\\d+$\\n\\n## Details\\n  * Drop all outgoing/incoming network traffic on instance for X minutes\\n  * Verify that the UnhealthyHostsCountAlarmName alarm is triggered\\n  * After the test's duration, the UnhealthyHostsCountAlarmName alarm should go back to green\\n\\n## Steps executed in normal flow\\n  * AssertAlarmToBeGreenBeforeTest\\n  * GetAsgInstanceIds\\n  * GetInstancesByPercentage\\n  * SimulateNetworkUnavailable\\n  * WaitForRecoveryTime\\n  * AssertAlarmTriggered\\n  * AssertAlarmToBeGreen\\n\\n## Outputs\\n  None\",\n  \"assumeRole\" : \"{{AutomationAssumeRole}}\",\n  \"parameters\" : {\n    \"AutomationAssumeRole\" : {\n      \"type\" : \"String\",\n      \"description\" : \"(Required) The ARN of the role that allows Automation to perform the actions on your behalf\",\n      \"allowedPattern\" : \"arn:aws:iam::\\\\d+:\\\\S+\"\n    },\n    \"AutoScalingGroupName\" : {\n      \"type\" : \"String\",\n      \"description\" : \"(Required) Name of auto scaling group\"\n    },\n    \"UnhealthyHostsCountAlarmName\" : {\n      \"type\" : \"String\",\n      \"description\" : \"(Required) An alarm for your Amazon Elastic Load Balancer that should be triggered when a new host becomes unhealthy. This alarm should be based on the UnHealthyHostCount metric, and its namespace will depend on the type of load balancer used.\"\n    },\n    \"PercentageOfInstances\" : {\n      \"type\" : \"Integer\",\n      \"description\" : \"(Optional) Percentage of ASG EC2 instances to be impacted, default is 1 percent to put minimum impact on EC2 instances in case if not provided\",\n      \"default\" : 1\n    },\n    \"DurationInMinutes\" : {\n      \"type\" : \"String\",\n      \"description\" : \"(Optional) The duration of the attack in minutes (default 5)\",\n      \"default\" : \"5\",\n      \"allowedPattern\" : \"^\\\\d+$\"\n    }\n  },\n  \"mainSteps\" : [ {\n    \"name\" : \"AssertAlarmToBeGreenBeforeTest\",\n    \"description\" : \"Ensure alarm is green before starting test. Fail if alarm is not green within expected time.\",\n    \"action\" : \"aws:waitForAwsResourceProperty\",\n    \"inputs\" : {\n      \"Service\" : \"cloudwatch\",\n      \"Api\" : \"DescribeAlarms\",\n      \"AlarmNames\" : [ \"{{UnhealthyHostsCountAlarmName}}\" ],\n      \"PropertySelector\" : \"$.MetricAlarms[0].StateValue\",\n      \"DesiredValues\" : [ \"OK\" ]\n    }\n  }, {\n    \"name\" : \"GetAsgInstanceIds\",\n    \"description\" : \"Get all healthy instances in ASG.\",\n    \"action\" : \"aws:executeScript\",\n    \"onFailure\" : \"Abort\",\n    \"outputs\" : [ {\n      \"Name\" : \"InstanceIds\",\n      \"Selector\" : \"$.Payload.InstanceIds\",\n      \"Type\" : \"StringList\"\n    } ],\n    \"inputs\" : {\n      \"Runtime\" : \"python3.8\",\n      \"Handler\" : \"get_healthy_instance_ids_in_asg\",\n      \"InputPayload\" : {\n        \"AutoScalingGroupName\" : \"{{AutoScalingGroupName}}\"\n      },\n      \"Script\" : \"import logging\\nimport random\\nimport time\\nfrom math import ceil\\n\\nimport boto3\\nfrom botocore.config import Config\\n\\nlogger = logging.getLogger(__name__)\\nlogger.setLevel(logging.INFO)\\n\\n\\n\\n\\ndef get_healthy_instance_ids_in_asg(events, context):\\n    if 'AutoScalingGroupName' not in events:\\n        raise KeyError('Requires AutoScalingGroupName in events')\\n    config = Config(retries={'max_attempts': 20, 'mode': 'standard'})\\n    autoscaling = boto3.client('autoscaling', config=config)\\n\\n    auto_scaling_groups = autoscaling.describe_auto_scaling_groups(\\n        AutoScalingGroupNames=[\\n            events['AutoScalingGroupName']\\n        ]\\n    )\\n\\n    # Take all healthy ASG EC2 instances\\n    asg_healthy_instances = []\\n    for instance in auto_scaling_groups['AutoScalingGroups'][0]['Instances']:\\n        if instance['HealthStatus'] == 'Healthy' and instance['LifecycleState'] == 'InService':\\n            asg_healthy_instances.append(instance['InstanceId'])\\n\\n    output = {}\\n    output['InstanceIds'] = asg_healthy_instances\\n    return output\"\n    }\n  }, {\n    \"name\" : \"GetInstancesByPercentage\",\n    \"description\" : \"Get instances based on input parameters\",\n    \"action\" : \"aws:executeScript\",\n    \"onFailure\" : \"Abort\",\n    \"outputs\" : [ {\n      \"Name\" : \"InstanceIds\",\n      \"Selector\" : \"$.Payload.InstanceIds\",\n      \"Type\" : \"StringList\"\n    } ],\n    \"inputs\" : {\n      \"Runtime\" : \"python3.8\",\n      \"Handler\" : \"get_instance_ids_by_percentage\",\n      \"InputPayload\" : {\n        \"InstanceIds\" : \"{{GetAsgInstanceIds.InstanceIds}}\",\n        \"Percentage\" : \"{{PercentageOfInstances}}\"\n      },\n      \"Script\" : \"import logging\\nimport random\\nimport time\\nfrom math import ceil\\n\\nimport boto3\\nfrom botocore.config import Config\\n\\nlogger = logging.getLogger(__name__)\\nlogger.setLevel(logging.INFO)\\n\\n\\n\\n\\ndef get_instance_ids_by_percentage(events, context):\\n    if 'InstanceIds' not in events or 'Percentage' not in events:\\n        raise KeyError('Requires InstanceIds and Percentage in events')\\n    instanceIds = events['InstanceIds']\\n    percentage = events['Percentage']\\n    instance_count = len(instanceIds)\\n    output = {}\\n    output['InstanceIds'] = []\\n    if instance_count < 1:\\n        raise Exception('No given EC2 instances')\\n    if percentage < 1:\\n        raise Exception('Given percentage should not be lower than 1%')\\n    instance_count = ceil(instance_count / 100 * percentage)\\n    for i in range(instance_count):\\n        output['InstanceIds'].append(instanceIds[i])\\n    return output\"\n    }\n  }, {\n    \"name\" : \"SimulateNetworkUnavailable\",\n    \"description\" : \"Run command document to inject network unavailable.\",\n    \"action\" : \"aws:runCommand\",\n    \"onFailure\" : \"Continue\",\n    \"timeoutSeconds\" : 60,\n    \"inputs\" : {\n      \"DocumentName\" : \"AWSResilienceHub-NetworkUnavailableCommand_2020-07-23\",\n      \"InstanceIds\" : [ \"{{GetInstancesByPercentage.InstanceIds}}\" ],\n      \"Parameters\" : {\n        \"DurationInMinutes\" : \"{{DurationInMinutes}}\"\n      },\n      \"TimeoutSeconds\" : 60\n    }\n  }, {\n    \"name\" : \"WaitForTestDuration\",\n    \"description\" : \"Wait for test duration.\",\n    \"action\" : \"aws:sleep\",\n    \"inputs\" : {\n      \"Duration\" : \"PT{{DurationInMinutes}}M\"\n    }\n  }, {\n    \"name\" : \"AssertAlarmTriggered\",\n    \"description\" : \"Verify multiple unhealthy instance alarm to be red during network unavailable.\",\n    \"action\" : \"aws:executeScript\",\n    \"onFailure\" : \"Abort\",\n    \"inputs\" : {\n      \"Runtime\" : \"python3.8\",\n      \"Handler\" : \"verify_alarm_triggered\",\n      \"InputPayload\" : {\n        \"AlarmName\" : \"{{UnhealthyHostsCountAlarmName}}\",\n        \"DurationInMinutes\" : \"{{DurationInMinutes}}\"\n      },\n      \"Script\" : \"import logging\\nimport time\\nfrom datetime import datetime, timedelta, timezone\\nfrom typing import Any, Callable, Iterator, List\\n\\nimport boto3\\nfrom botocore.config import Config\\n\\nboto3_config = Config(retries={'max_attempts': 20, 'mode': 'standard'})\\n\\nPUT_METRIC_ALARM_PARAMS = ['AlarmName', 'AlarmDescription', 'ActionsEnabled', 'OKActions',\\n                           'AlarmActions', 'InsufficientDataActions', 'MetricName', 'Namespace', 'Statistic',\\n                           'ExtendedStatistic',\\n                           'Dimensions', 'Period', 'Unit', 'EvaluationPeriods', 'DatapointsToAlarm',\\n                           'Threshold', 'ComparisonOperator', 'TreatMissingData', 'EvaluateLowSampleCountPercentile',\\n                           'Metrics', 'Tags', 'ThresholdMetricId']\\n\\n\\n\\n\\ndef verify_alarm_triggered(events, context):\\n    \\\"\\\"\\\"\\n    Verify if alarm triggered\\n    \\\"\\\"\\\"\\n    if 'AlarmName' not in events or ('DurationInMinutes' not in events and 'DurationInSeconds' not in events):\\n        raise KeyError('Requires AlarmName and either DurationInMinutes or DurationInSeconds in events')\\n\\n    cw = boto3.client('cloudwatch', config=boto3_config)\\n\\n    if 'DurationInMinutes' in events:\\n        start_date = datetime.now() - timedelta(minutes=int(events['DurationInMinutes']))\\n    else:\\n        start_date = datetime.now() - timedelta(seconds=int(events['DurationInSeconds']))\\n\\n    response = cw.describe_alarm_history(\\n        AlarmName=events['AlarmName'],\\n        HistoryItemType='StateUpdate',\\n        MaxRecords=5,\\n        ScanBy='TimestampDescending',\\n        StartDate=start_date)\\n\\n    for alarm_history_item in response['AlarmHistoryItems']:\\n        if alarm_history_item['HistorySummary'] == \\\"Alarm updated from OK to ALARM\\\":\\n            return\\n\\n    raise Exception('Alarm was not triggered')\"\n    }\n  }, {\n    \"name\" : \"AssertAlarmToBeGreen\",\n    \"description\" : \"Verify multiple unhealthy instance alarm to be ok\",\n    \"action\" : \"aws:waitForAwsResourceProperty\",\n    \"maxAttempts\" : 1,\n    \"timeoutSeconds\" : 600,\n    \"inputs\" : {\n      \"Service\" : \"cloudwatch\",\n      \"Api\" : \"DescribeAlarms\",\n      \"AlarmNames\" : [ \"{{UnhealthyHostsCountAlarmName}}\" ],\n      \"PropertySelector\" : \"$.MetricAlarms[0].StateValue\",\n      \"DesiredValues\" : [ \"OK\" ]\n    },\n    \"isEnd\" : true\n  } ]\n}",
  "CreatedDate": "2023-06-27T13:56:50.386Z",
  "DisplayName": null,
  "DocumentFormat": {
    "Value": "JSON"
  },
  "DocumentType": {
    "Value": "Automation"
  },
  "DocumentVersion": "1",
  "Name": "AWSResilienceHub-SimulateNetworkUnavailableInAsgTest_2020-07-23",
  "Requires": [],
  "ReviewStatus": null,
  "Status": {
    "Value": "Active"
  },
  "StatusInformation": null,
  "VersionName": null,
  "ResponseMetadata": {
    "RequestId": "0634cd13-9db5-4d18-9a58-cd5db5512b2e",
    "Metadata": {},
    "ChecksumAlgorithm": 0,
    "ChecksumValidationStatus": 0
  },
  "ContentLength": 11467,
  "HttpStatusCode": 200,
  "LoggedAt": "2023-06-28T07:12:42.3330202+00:00"
}
